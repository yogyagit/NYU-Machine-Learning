# -*- coding: utf-8 -*-
"""ys5250 ML Assignment 3 Q2 Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lCYaDBTr7EJGlaGrD6lFAEaSMjJzlacj
"""

import scipy.io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

#importing dataset
dataset = scipy.io.loadmat('dataset.mat')

#creating a dataframe
df1 = pd.DataFrame(dataset['X'] , columns = ['x1' , 'x2', 'x3', 'x4'])
df2 = pd.DataFrame(dataset['Y'] , columns = ['y'])

#Extractiong X and Y from the dataframe
X = pd.DataFrame(df1.iloc[ : , :4])
Y = pd.DataFrame(df2.iloc[ : , :1])

#splitting the data into data for train and test
X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, random_state = 1, test_size = 0.5)

test_len = len(Y_Test)

#Flattening the y_train and y_test vectors to pass to svm predict()
fl_Y_Train = np.ravel(Y_Train)
fl_Y_Test = np.ravel(Y_Test)

# List for testing out different C values
C = [0.01*i for i in range(1,1000,20)]

#Linear Kernel
linear_accuracy = list()

for c in C:
  linear_classifier = svm.SVC(kernel = 'linear', C = c, random_state = 1)
  #Training the Linear SVM model
  linear_classifier.fit(X_Train, fl_Y_Train)    
  #Predicting using test data
  prediction = linear_classifier.predict(X_Test)    
  #Calculating the accuracy                                  
  linear_accuracy.append((np.sum(prediction == fl_Y_Test))/test_len)

#Polynomial Kernel
poly_accuracy = [[] for i in range(4)]

for c in C:
  for exp in range(2, 6):
    poly_classifier = svm.SVC(kernel = 'poly', C = c, degree = exp, random_state = 1)
    #Training the Polynomial SVM model
    poly_classifier.fit(X_Train, fl_Y_Train)   
    #Predicting using test data
    prediction = poly_classifier.predict(X_Test)
    #Calculating the accuracy for each degree of the polynomial
    poly_accuracy[exp-2].append((np.sum(prediction == fl_Y_Test))/test_len)

#RBF Kernel
Gamma = [0.01, 0.1, 0.7, 1, 3, 7, 21]
rbf_accuracy = [[] for i in range(len(Gamma))] 

for c in C:
  for sig in range(len(Gamma)):
    rbf_classifier = svm.SVC(kernel = 'rbf', C = c, gamma = Gamma[sig] , random_state = 1)
    #Training the RBF SVM model
    rbf_classifier.fit(X_Train, fl_Y_Train)
    #Predicting using test data
    prediction = rbf_classifier.predict(X_Test)
    #Calculating the accuracy for each gamma value 
    rbf_accuracy[sig].append((np.sum(prediction == fl_Y_Test))/test_len)

#Plotting for Linear Kernel
print('Maximum accuracy for linear kernel:', np.max(linear_accuracy), 'for C=', C[linear_accuracy.index(np.max(linear_accuracy))] )
fig1, linear = plt.subplots(1, 1)
linear.plot(C, linear_accuracy,'x')
linear.grid()
linear.set(xlabel='C', ylabel='Linear Kernel Test Accuracy')
linear.set_title('Accuracy for Linear SVM')
plt.show()

#Plotting for Polynomial Kernel with degree 2
fig2, poly1 = plt.subplots(1, 1)
print('Maximum accuracy for polynomial kernel with degree: 2 is',np.max(poly_accuracy[0]), 'for C=', C[poly_accuracy[0].index(np.max(poly_accuracy[0]))])
poly1.plot(C, poly_accuracy[0],'x')
poly1.grid()
poly1.set(xlabel='C', ylabel='Polynomial Kernel Test Accuracy')
poly1.set_title('Accuracy for Polynomial SVM with degree 2')
plt.show()

#Plotting for Polynomial Kernel with degree 3
fig3, poly2 = plt.subplots(1, 1)
print('Maximum accuracy for polynomial kernel with degree: 3 is',np.max(poly_accuracy[1]), 'for C=', C[poly_accuracy[1].index(np.max(poly_accuracy[1]))])
poly2.plot(C, poly_accuracy[1],'x')
poly2.grid()
poly2.set(xlabel='C', ylabel='Polynomial Kernel Test Accuracy')
poly2.set_title('Accuracy for Polynomial SVM with degree 3')
plt.show()

#Plotting for Polynomial Kernel with degree 4
fig4, poly3 = plt.subplots(1, 1)
print('Maximum accuracy for polynomial kernel with degree: 4 is',np.max(poly_accuracy[2]), 'for C=', C[poly_accuracy[2].index(np.max(poly_accuracy[2]))])
poly3.plot(C, poly_accuracy[2],'x')
poly3.grid()
poly3.set(xlabel='C', ylabel='Polynomial Kernel Test Accuracy')
poly3.set_title('Accuracy for Polynomial SVM with degree 4')
plt.show()

#Plotting for Polynomial Kernel with degree 5
fig5, poly4 = plt.subplots(1, 1)
print('Maximum accuracy for polynomial kernel with degree: 5 is',np.max(poly_accuracy[3]), 'for C=', C[poly_accuracy[3].index(np.max(poly_accuracy[3]))])
poly4.plot(C, poly_accuracy[3],'x')
poly4.grid()
poly4.set(xlabel='C', ylabel='Polynomial Kernel Test Accuracy')
poly4.set_title('Accuracy for Polynomial SVM with degree 5')
plt.show()

#Plotting for RBF Kernel gamma 0.01
fig2, rbf1 = plt.subplots(1, 1)
print('Maximum accuracy for RBF kernel with gamma 0.01 is',np.max(rbf_accuracy[0]), 'for C=', C[rbf_accuracy[0].index(np.max(rbf_accuracy[0]))])
rbf1.plot(C, rbf_accuracy[0],'x')
rbf1.grid()
rbf1.set(xlabel='C', ylabel='RBF Kernel Test Accuracy')
rbf1.set_title('Accuracy for RBF SVM with gamma 0.01')
plt.show()

#Plotting for RBF Kernel gamma 0.1
fig3, rbf2 = plt.subplots(1, 1)
print('Maximum accuracy for RBF kernel with gamma 0.1 is',np.max(rbf_accuracy[1]), 'for C=', C[rbf_accuracy[1].index(np.max(rbf_accuracy[1]))])
rbf2.plot(C, rbf_accuracy[1],'x')
rbf2.grid()
rbf2.set(xlabel='C', ylabel='RBF Kernel Test Accuracy')
rbf2.set_title('Accuracy for RBF SVM with gamma 0.1')
plt.show()

#Plotting for RBF Kernel gamma 0.7
fig4, rbf3 = plt.subplots(1, 1)
print('Maximum accuracy for RBF kernel with gamma 0.7 is',np.max(rbf_accuracy[2]), 'for C=', C[rbf_accuracy[2].index(np.max(rbf_accuracy[2]))])
rbf3.plot(C, rbf_accuracy[2],'x')
rbf3.grid()
rbf3.set(xlabel='C', ylabel='RBF Kernel Test Accuracy')
rbf3.set_title('Accuracy for RBF SVM with gamma 0.7')
plt.show()

#Plotting for RBF Kernel gamma 1
fig5, rbf4 = plt.subplots(1, 1)
print('Maximum accuracy for RBF kernel with gamma 1 is',np.max(rbf_accuracy[3]), 'for C=', C[rbf_accuracy[3].index(np.max(rbf_accuracy[3]))])
rbf4.plot(C, rbf_accuracy[3],'x')
rbf4.grid()
rbf4.set(xlabel='C', ylabel='RBF Kernel Test Accuracy')
rbf4.set_title('Accuracy for RBF SVM with gamma 1')
plt.show()

#Plotting for RBF Kernel gamma 3
fig6, rbf5 = plt.subplots(1, 1)
print('Maximum accuracy for RBF kernel with gamma 3 is',np.max(rbf_accuracy[4]), 'for C=', C[rbf_accuracy[4].index(np.max(rbf_accuracy[4]))])
rbf5.plot(C, rbf_accuracy[4],'x')
rbf5.grid()
rbf5.set(xlabel='C', ylabel='RBF Kernel Test Accuracy')
rbf5.set_title('Accuracy for RBF SVM with gamma 3')
plt.show()

#Plotting for RBF Kernel gamma 7
fig7, rbf6 = plt.subplots(1, 1)
print('Maximum accuracy for RBF kernel with gamma 7 is',np.max(rbf_accuracy[5]), 'for C=', C[rbf_accuracy[5].index(np.max(rbf_accuracy[5]))])
rbf6.plot(C, rbf_accuracy[5],'x')
rbf6.grid()
rbf6.set(xlabel='C', ylabel='RBF Kernel Test Accuracy')
rbf6.set_title('Accuracy for RBF SVM with gamma 7')
plt.show()

#Plotting for RBF Kernel gamma 21
fig7, rbf7 = plt.subplots(1, 1)
print('Maximum accuracy for RBF kernel with gamma 21 is',np.max(rbf_accuracy[6]), 'for C=', C[rbf_accuracy[6].index(np.max(rbf_accuracy[6]))])
rbf7.plot(C, rbf_accuracy[6],'x')
rbf7.grid()
rbf7.set(xlabel='C', ylabel='RBF Kernel Test Accuracy')
rbf7.set_title('Accuracy for RBF SVM with gamma 21')
plt.show()

